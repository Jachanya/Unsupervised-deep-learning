{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conditional PixelCnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opitm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorizontalStack(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, filter_size, mask = 'A',stride = 1, padding = 0, bias = False):\n",
    "        super().__init__(in_channels, out_channels, (1,filter_size), stride, padding, bias = False)\n",
    "        self.padding = filter_size\n",
    "        self.mask = mask\n",
    "        #self.register_buffer('mask', torch.zeros_like(self.weight))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x <- B C H W\n",
    "        '''\n",
    "        if self.mask == 'A':\n",
    "            m = nn.ZeroPad2d((self.padding,0,0,0))\n",
    "            x = m(x)\n",
    "            x = F.conv2d(x, self.weight)\n",
    "            x = x[:,:,:,:-1]\n",
    "        \n",
    "        else:\n",
    "            m = nn.ZeroPad2d((self.padding-1, 0,0,0))\n",
    "            x = m(x)\n",
    "            x = F.conv2d(x, self.weight)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerticalStack(nn.Conv2d):\n",
    "    def __init__(self,in_channels, out_channels, filter_size, stride = 1, padding = 0, bias = None):\n",
    "        super().__init__(in_channels, out_channels, filter_size, stride, padding, bias)\n",
    "        assert filter_size % 2 != 0, 'Only odd filter size accepted'\n",
    "        self.padding = filter_size\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        X <- B C H W\n",
    "        '''\n",
    "        #Use only odd kernel shapes\n",
    "        m = nn.ZeroPad2d((self.padding//2,self.padding//2,self.padding, 0))\n",
    "        x = m(x)\n",
    "        x = F.conv2d(x, self.weight)\n",
    "        #crop_val = -(self.padding + 1)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, feature_size, mask = 'A'):\n",
    "        super(PixelCNNBlock, self).__init__()\n",
    "        self.pad = feature_size\n",
    "        self.vstack = VerticalStack(in_channels, in_channels * 2, feature_size)\n",
    "        self.hstack = HorizontalStack(in_channels, in_channels * 2, feature_size, mask = 'A')\n",
    "        self.conv1 = nn.Conv2d(in_channels * 2, in_channels * 2, 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, v, h):\n",
    "        v_p = self.vstack(v)\n",
    "        h_p = self.hstack(h)\n",
    "        h_p = self.conv1(v_p[:,:,:-1,:]) + h_p\n",
    "        \n",
    "\n",
    "        new_h_p = torch.tanh(h_p[:,::2,:,:]) * torch.sigmoid(h_p[:,1::2,:,:])\n",
    "\n",
    "        new_h_p = self.conv2(new_h_p) + h\n",
    "        v_p = torch.tanh(v_p[:,::2,1:,:]) * torch.sigmoid(v_p[:,1::2,1:,:])\n",
    "        return new_h_p, v_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, filter_size, support = 255, layer = 10):\n",
    "        super(PixelCNN, self).__init__()\n",
    "        lay1 = [PixelCNNBlock(in_channels, out_channels, filter_size) for i in range(layer)]\n",
    "        self.models = nn.ModuleList(lay1)\n",
    "        self.conv1 = nn.Conv2d(in_channels, support, 1)\n",
    "        \n",
    "    def forward(self, h, v):\n",
    "        h = (h - h.mean()) / h.std()\n",
    "        v = (v - v.mean()) / v.std()\n",
    "        for model in self.models:\n",
    "            h, v = model(h, v)\n",
    "        h = self.conv1(h)\n",
    "        return h,v\n",
    "    \n",
    "    def loss(self, output, target):\n",
    "        return F.cross_entropy(output, target)\n",
    "\n",
    "    def sample(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "#print(testset[0][0] * 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck truck plane ship \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "model = PixelCNN(1,16,3,layer = 30)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.128\n",
      "[1,  4000] loss: 1.209\n",
      "[1,  6000] loss: 1.195\n",
      "[1,  8000] loss: 1.185\n",
      "[1, 10000] loss: 1.182\n",
      "[1, 12000] loss: 1.178\n",
      "[1, 14000] loss: 1.175\n",
      "[2,  2000] loss: 1.175\n",
      "[2,  4000] loss: 1.172\n",
      "[2,  6000] loss: 1.162\n",
      "[2,  8000] loss: 1.165\n",
      "[2, 10000] loss: 1.168\n",
      "[2, 12000] loss: 1.165\n",
      "[2, 14000] loss: 1.163\n",
      "[3,  2000] loss: 1.164\n",
      "[3,  4000] loss: 1.164\n",
      "[3,  6000] loss: 1.159\n",
      "[3,  8000] loss: 1.162\n",
      "[3, 10000] loss: 1.160\n",
      "[3, 12000] loss: 1.155\n",
      "[3, 14000] loss: 1.156\n",
      "[4,  2000] loss: 1.159\n",
      "[4,  4000] loss: 1.159\n",
      "[4,  6000] loss: 1.153\n",
      "[4,  8000] loss: 1.155\n",
      "[4, 10000] loss: 1.155\n",
      "[4, 12000] loss: 1.152\n",
      "[4, 14000] loss: 1.153\n",
      "[5,  2000] loss: 1.155\n",
      "[5,  4000] loss: 1.150\n",
      "[5,  6000] loss: 1.155\n",
      "[5,  8000] loss: 1.152\n",
      "[5, 10000] loss: 1.149\n",
      "[5, 12000] loss: 1.155\n",
      "[5, 14000] loss: 1.144\n",
      "[6,  2000] loss: 1.147\n",
      "[6,  4000] loss: 1.153\n",
      "[6,  6000] loss: 1.145\n",
      "[6,  8000] loss: 1.149\n",
      "[6, 10000] loss: 1.146\n",
      "[6, 12000] loss: 1.152\n",
      "[6, 14000] loss: 1.147\n",
      "[7,  2000] loss: 1.147\n",
      "[7,  4000] loss: 1.146\n",
      "[7,  6000] loss: 1.148\n",
      "[7,  8000] loss: 1.146\n",
      "[7, 10000] loss: 1.149\n",
      "[7, 12000] loss: 1.139\n",
      "[7, 14000] loss: 1.145\n",
      "[8,  2000] loss: 1.144\n",
      "[8,  4000] loss: 1.142\n",
      "[8,  6000] loss: 1.141\n",
      "[8,  8000] loss: 1.146\n",
      "[8, 10000] loss: 1.145\n",
      "[8, 12000] loss: 1.140\n",
      "[8, 14000] loss: 1.137\n",
      "[9,  2000] loss: 1.137\n",
      "[9,  4000] loss: 1.136\n",
      "[9,  6000] loss: 1.140\n",
      "[9,  8000] loss: 1.140\n",
      "[9, 10000] loss: 1.137\n",
      "[9, 12000] loss: 1.138\n",
      "[9, 14000] loss: 1.134\n",
      "[10,  2000] loss: 1.137\n",
      "[10,  4000] loss: 1.126\n",
      "[10,  6000] loss: 1.124\n",
      "[10,  8000] loss: 1.118\n",
      "[10, 10000] loss: 1.106\n",
      "[10, 12000] loss: 1.063\n",
      "[10, 14000] loss: 0.989\n",
      "[11,  2000] loss: 0.961\n",
      "[11,  4000] loss: 0.952\n",
      "[11,  6000] loss: 0.941\n",
      "[11,  8000] loss: 0.941\n",
      "[11, 10000] loss: 0.937\n",
      "[11, 12000] loss: 0.936\n",
      "[11, 14000] loss: 0.930\n",
      "[12,  2000] loss: 0.930\n",
      "[12,  4000] loss: 0.930\n",
      "[12,  6000] loss: 0.924\n",
      "[12,  8000] loss: 0.926\n",
      "[12, 10000] loss: 0.922\n",
      "[12, 12000] loss: 0.919\n",
      "[12, 14000] loss: 0.924\n",
      "[13,  2000] loss: 0.921\n",
      "[13,  4000] loss: 0.918\n",
      "[13,  6000] loss: 0.921\n",
      "[13,  8000] loss: 0.919\n",
      "[13, 10000] loss: 0.916\n",
      "[13, 12000] loss: 0.917\n",
      "[13, 14000] loss: 0.919\n",
      "[14,  2000] loss: 0.911\n",
      "[14,  4000] loss: 0.914\n",
      "[14,  6000] loss: 0.918\n",
      "[14,  8000] loss: 0.913\n",
      "[14, 10000] loss: 0.917\n",
      "[14, 12000] loss: 0.917\n",
      "[14, 14000] loss: 0.917\n",
      "[15,  2000] loss: 0.915\n",
      "[15,  4000] loss: 0.915\n",
      "[15,  6000] loss: 0.914\n",
      "[15,  8000] loss: 0.910\n",
      "[15, 10000] loss: 0.910\n",
      "[15, 12000] loss: 0.912\n",
      "[15, 14000] loss: 0.912\n",
      "[16,  2000] loss: 0.912\n",
      "[16,  4000] loss: 0.911\n",
      "[16,  6000] loss: 0.910\n",
      "[16,  8000] loss: 0.913\n",
      "[16, 10000] loss: 0.910\n",
      "[16, 12000] loss: 0.908\n",
      "[16, 14000] loss: 0.914\n",
      "[17,  2000] loss: 0.911\n",
      "[17,  4000] loss: 0.908\n",
      "[17,  6000] loss: 0.914\n",
      "[17,  8000] loss: 0.903\n",
      "[17, 10000] loss: 0.905\n",
      "[17, 12000] loss: 0.908\n",
      "[17, 14000] loss: 0.910\n",
      "[18,  2000] loss: 0.908\n",
      "[18,  4000] loss: 0.908\n",
      "[18,  6000] loss: 0.908\n",
      "[18,  8000] loss: 0.912\n",
      "[18, 10000] loss: 0.907\n",
      "[18, 12000] loss: 0.904\n",
      "[18, 14000] loss: 0.904\n",
      "[19,  2000] loss: 0.906\n",
      "[19,  4000] loss: 0.910\n",
      "[19,  6000] loss: 0.911\n",
      "[19,  8000] loss: 0.904\n",
      "[19, 10000] loss: 0.904\n",
      "[19, 12000] loss: 0.907\n",
      "[19, 14000] loss: 0.902\n",
      "[20,  2000] loss: 0.904\n",
      "[20,  4000] loss: 0.909\n",
      "[20,  6000] loss: 0.902\n",
      "[20,  8000] loss: 0.904\n",
      "[20, 10000] loss: 0.907\n",
      "[20, 12000] loss: 0.908\n",
      "[20, 14000] loss: 0.904\n",
      "[21,  2000] loss: 0.904\n",
      "[21,  4000] loss: 0.903\n",
      "[21,  6000] loss: 0.906\n",
      "[21,  8000] loss: 0.905\n",
      "[21, 10000] loss: 0.899\n",
      "[21, 12000] loss: 0.908\n",
      "[21, 14000] loss: 0.904\n",
      "[22,  2000] loss: 0.906\n",
      "[22,  4000] loss: 0.905\n",
      "[22,  6000] loss: 0.905\n",
      "[22,  8000] loss: 0.897\n",
      "[22, 10000] loss: 0.902\n",
      "[22, 12000] loss: 0.904\n",
      "[22, 14000] loss: 0.907\n",
      "[23,  2000] loss: 0.906\n",
      "[23,  4000] loss: 0.899\n",
      "[23,  6000] loss: 0.902\n",
      "[23,  8000] loss: 0.902\n",
      "[23, 10000] loss: 0.906\n",
      "[23, 12000] loss: 0.904\n",
      "[23, 14000] loss: 0.902\n",
      "[24,  2000] loss: 0.900\n",
      "[24,  4000] loss: 0.905\n",
      "[24,  6000] loss: 0.901\n",
      "[24,  8000] loss: 0.899\n",
      "[24, 10000] loss: 0.898\n",
      "[24, 12000] loss: 0.907\n",
      "[24, 14000] loss: 0.902\n",
      "[25,  2000] loss: 0.906\n",
      "[25,  4000] loss: 0.903\n",
      "[25,  6000] loss: 0.898\n",
      "[25,  8000] loss: 0.901\n",
      "[25, 10000] loss: 0.898\n",
      "[25, 12000] loss: 0.902\n",
      "[25, 14000] loss: 0.901\n",
      "[26,  2000] loss: 0.901\n",
      "[26,  4000] loss: 0.898\n",
      "[26,  6000] loss: 0.898\n",
      "[26,  8000] loss: 0.901\n",
      "[26, 10000] loss: 0.903\n",
      "[26, 12000] loss: 0.901\n",
      "[26, 14000] loss: 0.902\n",
      "[27,  2000] loss: 0.902\n",
      "[27,  4000] loss: 0.901\n",
      "[27,  6000] loss: 0.902\n",
      "[27,  8000] loss: 0.899\n",
      "[27, 10000] loss: 0.900\n",
      "[27, 12000] loss: 0.899\n",
      "[27, 14000] loss: 0.898\n",
      "[28,  2000] loss: 0.900\n",
      "[28,  4000] loss: 0.898\n",
      "[28,  6000] loss: 0.899\n",
      "[28,  8000] loss: 0.897\n",
      "[28, 10000] loss: 0.904\n",
      "[28, 12000] loss: 0.898\n",
      "[28, 14000] loss: 0.899\n",
      "[29,  2000] loss: 0.904\n",
      "[29,  4000] loss: 0.897\n",
      "[29,  6000] loss: 0.899\n",
      "[29,  8000] loss: 0.894\n",
      "[29, 10000] loss: 0.899\n",
      "[29, 12000] loss: 0.900\n",
      "[29, 14000] loss: 0.902\n",
      "[30,  2000] loss: 0.899\n",
      "[30,  4000] loss: 0.899\n",
      "[30,  6000] loss: 0.903\n",
      "[30,  8000] loss: 0.901\n",
      "[30, 10000] loss: 0.898\n",
      "[30, 12000] loss: 0.897\n",
      "[30, 14000] loss: 0.897\n",
      "[31,  2000] loss: 0.902\n",
      "[31,  4000] loss: 0.896\n",
      "[31,  6000] loss: 0.898\n",
      "[31,  8000] loss: 0.897\n",
      "[31, 10000] loss: 0.895\n",
      "[31, 12000] loss: 0.903\n",
      "[31, 14000] loss: 0.897\n",
      "[32,  2000] loss: 0.900\n",
      "[32,  4000] loss: 0.901\n",
      "[32,  6000] loss: 0.900\n"
     ]
    }
   ],
   "source": [
    "#inputs, labels = dataiter.next()\n",
    "for epoch in range(1000):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(inputs, inputs)\n",
    "        #print((inputs * 254).long()[0])\n",
    "        #print(outputs.shape)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, (inputs * 254).squeeze(1).long().detach())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
