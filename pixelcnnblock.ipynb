{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerticalStack(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride = 1, bias = False):\n",
    "        super(VerticalStack, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.pad = nn.ZeroPad2d(((kernel_size[1]-1)//2, (kernel_size[1]-1)//2, kernel_size[0]-1, 0))\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride = 1,bias = bias)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(self.conv(self.pad(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_down(x):\n",
    "    x = x[:,:,:-1,:]\n",
    "    pad = nn.ZeroPad2d((0,0,1,0))\n",
    "    x = pad(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorizontalStack(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride = 1,bias = False):\n",
    "        super(HorizontalStack, self).__init__()\n",
    "        \n",
    "        assert len(kernel_size) == 2, 'kernel should be tuple of size 2'\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.pad = nn.ZeroPad2d((kernel_size[1] - 1, 0, 0, 0))\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride = 1,bias = bias)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "    def forward(self, x):\n",
    "        x = self.bn(self.conv(self.pad(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_right(x):\n",
    "    x = x[:,:,:,:-1]\n",
    "    pad = nn.ZeroPad2d((1,0,0,0))\n",
    "    x = pad(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockPixelCNN(nn.Module):\n",
    "    def __init__(self,in_channels, kernel_size_v, kernel_size_h, stride = 1, bias = False):\n",
    "        super(BlockPixelCNN, self).__init__()\n",
    "        \n",
    "        #assert out_channels % 2 == 0, 'out_channel has to be divisible by 2'\n",
    "        self.vert = VerticalStack(in_channels, in_channels*2, kernel_size_v, stride = 1, bias = False)\n",
    "        self.hor = HorizontalStack(in_channels, in_channels*2, kernel_size_h, stride = 1, bias = False)\n",
    "        self.conv_v_h = nn.Conv2d(in_channels*2, in_channels*2, 1, 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels*2)\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, 1, 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "        \n",
    "        \n",
    "    def forward(self, v, h):\n",
    "        v_1, output = self.vertical(v)\n",
    "        #print(shift_down(v).shape)\n",
    "        h = self.horizontal(h, output) + h #+ shift_down(v) #experiment with residual\n",
    "        return v_1, h\n",
    "    \n",
    "    def horizontal(self, x, x_vertical):\n",
    "        x = (x_vertical) + self.hor(x)\n",
    "        x = torch.sigmoid(x[:, 1::2, :,:]) * torch.tanh(x[:,0::2,:,:])\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n",
    "        \n",
    "    def vertical(self, x):\n",
    "        x = self.vert(x)\n",
    "        output = self.conv_v_h(shift_down(x))\n",
    "        output = self.bn1(output)\n",
    "        x = torch.sigmoid(x[:,1::2,:,:]) * torch.tanh(x[:,0::2,:,:])\n",
    "        return x, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self,input_channels, k_channels, v_channels, heads = 4, device = 'cuda'):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        \n",
    "        self.input_channels = input_channels\n",
    "        self.k_channels = k_channels\n",
    "        self.v_channels = v_channels\n",
    "        self.heads = heads\n",
    "        \n",
    "        self.conv_q = nn.Conv2d(input_channels, k_channels * heads, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.conv_k = nn.Conv2d(input_channels, k_channels * heads, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.conv_v = nn.Conv2d(input_channels, v_channels * heads, kernel_size = 1, stride = 1, bias = False)\n",
    "        \n",
    "        self.conv_h = nn.Conv2d(v_channels * heads, v_channels,  kernel_size = 1, stride = 1,bias = False)\n",
    "        \n",
    "        self.device = device\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x-> BCHW\n",
    "        '''\n",
    "        \n",
    "        query = self.conv_q(x)\n",
    "        key = self.conv_k(x)\n",
    "        value = self.conv_v(x)\n",
    "        \n",
    "        query_shape = query.shape\n",
    "        bs = query.size(0)\n",
    "        \n",
    "        query = query.view(bs, self.heads , query_shape[1]//self.heads , query_shape[2] * query_shape[3])#.reshape(bs, self.heads ,query_shape[1]//self.heads, -1)\n",
    "        query = query.permute(0,1,3,2).view(query_shape[0] * self.heads, query_shape[2] * query_shape[3] , query_shape[1]//self.heads)\n",
    "        \n",
    "        key = key.view(bs, self.heads , query_shape[1]//self.heads , query_shape[2] * query_shape[3])#.reshape(bs, self.heads ,query_shape[1]//self.heads, -1)\n",
    "        key = key.view(query_shape[0] * self.heads, query_shape[1]//self.heads , query_shape[2] * query_shape[3] )\n",
    "        \n",
    "        \n",
    "        attn = torch.bmm(query, key)\n",
    "        \n",
    "        \n",
    "        attn = attn / torch.sqrt(torch.FloatTensor([self.k_channels]).to(attn.device))\n",
    "        \n",
    "        mask = (torch.tril(torch.ones_like((attn)), diagonal = -1) * -100000).permute(0,2,1)\n",
    "        #print(torch.where(attn > 0))\n",
    "        \n",
    "        #print(attn + mask)\n",
    "        attn = attn + mask\n",
    "        \n",
    "        \n",
    "        attn = F.softmax(attn, dim = -1)\n",
    "        \n",
    "        #plt.imshow(attn[0,:,:].detach())\n",
    "        #plt.show()\n",
    "        \n",
    "        value_shape = value.shape\n",
    "        value = value.view(value_shape[0] ,self.heads, value_shape[1]//self.heads, value_shape[2] * value_shape[3])\n",
    "        value = value.permute(0,1,3,2).view(value_shape[0] * self.heads ,value_shape[2] * value_shape[3], value_shape[1]//self.heads)\n",
    "        \n",
    "        output = torch.bmm(attn, value)\n",
    "        \n",
    "        #print(output.shape)\n",
    "        \n",
    "        output = output.view(value_shape[0], self.heads, value_shape[2] * value_shape[3] , self.v_channels).contiguous()\n",
    "\n",
    "        output = output.permute(0,1,3,2).contiguous().view(value_shape[0], self.heads * self.v_channels, value_shape[2] , value_shape[3]).contiguous()\n",
    "        \n",
    "        output = self.conv_h(output)\n",
    "        #output = output.reshape(value_shape[0], -1, value_shape[2], value_shape[3])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelSNAILBlock(nn.Module):\n",
    "    def __init__(self, in_channels,aux_channels, k_size, v_size):\n",
    "        super(PixelSNAILBlock, self).__init__()\n",
    "        self.cnn_block = nn.ModuleList([BlockPixelCNN(in_channels, (2,3), (1,3)) for i in range(4)])\n",
    "        self.attn_block = AttentionBlock(in_channels+aux_channels, k_size, v_size)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv2 = nn.Conv2d(v_size, in_channels, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv3 = nn.Conv2d(in_channels, in_channels, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.bn3 = nn.BatchNorm2d(in_channels)\n",
    "        \n",
    "    def forward(self, resblock_v,resblock_h, main_input):\n",
    "        \n",
    "        for i in range(len(self.cnn_block)):\n",
    "            resblock_v, resblock_h = self.cnn_block[i](resblock_v, resblock_h)\n",
    "        \n",
    "        attn = torch.cat((resblock_h, shift_down(main_input)), dim = 1)\n",
    "        attn = self.attn_block(attn)\n",
    "        \n",
    "        resblock_h = F.elu(self.bn1(self.conv1(F.elu(resblock_h))))\n",
    "        #print(resblock_h)\n",
    "        attn = F.elu(self.bn2(self.conv2(F.elu(attn))))\n",
    "        \n",
    "        resblock_h = resblock_h + attn\n",
    "        resblock_h = F.elu(self.bn3(self.conv3(F.elu(resblock_h))))\n",
    "        \n",
    "        return resblock_v, resblock_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelSNAIL(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size , v_size , mixtures = 10, m_blocks = 4):\n",
    "        super(PixelSNAIL, self).__init__()\n",
    "        self.vert = VerticalStack(in_channels,out_channels,(2,3))\n",
    "        self.hor = HorizontalStack(in_channels,out_channels,(1,3))\n",
    "        self.model = nn.ModuleList([PixelSNAILBlock(out_channels, in_channels, k_size , v_size) for i in range(m_blocks)])\n",
    "        \n",
    "        #self.conv1 = nn.Conv2d(out_channels, mixtures * 3, kernel_size = 1, stride = 1)\n",
    "        self.conv1 = nn.Conv2d(out_channels, 1, kernel_size = 1, stride = 1, bias = False)\n",
    "    def forward(self, inputs):\n",
    "        vert = self.vert(inputs)\n",
    "        hor = shift_right(self.hor(inputs))\n",
    "        \n",
    "        for i in range(len(self.model)):\n",
    "            vert, hor = self.model[i](vert, hor, inputs)\n",
    "            \n",
    "        hor = self.conv1(F.elu(hor))\n",
    "        return hor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing for unnormalized\n",
    "def discretized_logistic_loss_1d(outputs, inputs, d =  255):\n",
    "    '''\n",
    "    outputs -> BDHW, where D is n_mixs * 3\n",
    "    inputs -> BCHW\n",
    "    d -> maximum support of the distribution\n",
    "    '''\n",
    "    \n",
    "    inputs = inputs.permute(0,2,3,1).contiguous()\n",
    "    outputs = outputs.permute(0,2,3,1).contiguous()\n",
    "    \n",
    "    input_shape = inputs.shape\n",
    "    n_mixs = int(outputs.shape[-1]/3)\n",
    "    \n",
    "    inv_scales = torch.exp(-outputs[:,:,:,n_mixs*2:n_mixs*3])\n",
    "    means = outputs[:,:,:,n_mixs*1:n_mixs*2]\n",
    "    logits = outputs[:,:,:,:n_mixs]\n",
    "    plus_in = inv_scales * (inputs + 0.5 - means)\n",
    "    min_in = inv_scales * (inputs - 0.5 - means)\n",
    "    \n",
    "    cdf_delta = plus_in - min_in\n",
    "    log_cdf_delta = torch.log(torch.clamp(cdf_delta, min = 1e-12))\n",
    "    \n",
    "    log_cdf_max = torch.log(torch.clamp(1-torch.sigmoid(inv_scales * (d - 1.5 - means)), min = 1e-12))\n",
    "    \n",
    "    log_cdf_min = torch.log(torch.clamp(torch.sigmoid(inv_scales * (0.5 - means)), min = 1e-12))\n",
    "    \n",
    "    inputs_log_probs = torch.where(inputs<0.001, log_cdf_min, torch.where(inputs > d -1 - 1e-3,\n",
    "                                                               log_cdf_max, log_cdf_delta))\n",
    "    \n",
    "    pi_log_probs = F.log_softmax(logits, dim = -1)\n",
    "    log_probs = inputs_log_probs + pi_log_probs\n",
    "    \n",
    "    return torch.logsumexp(log_probs, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelSNAIL(1,256, 16, 128, m_blocks =20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.]], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eb81770d00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "inputs = torch.zeros(1,1,32,32)\n",
    "\n",
    "inputs[:,:,10,15] = 1\n",
    "\n",
    "output = model(inputs)\n",
    "print(output[:,:,10,15])\n",
    "\n",
    "plt.imshow(output.squeeze(0).detach().permute(1,2,0)[:,:,:3].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johna\\anaconda4\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "#print(testset[0][0] * 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "#print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PixelSNAIL(1,256, 16, 128, m_blocks =1).to(device = 'cuda')\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_fn  = nn.BCELoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-39b2961f3651>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#print(inputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;31m#print(loss.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;31m# All strings are unicode in Python 3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[1;34m(inp)\u001b[0m\n\u001b[0;32m    379\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m                     \u001b[0mtensor_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mformatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mne\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "for epoch in range(4):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        # print statistics\n",
    "        #print(outputs)\n",
    "        #print(inputs)\n",
    "        loss = F.mse_loss(outputs, inputs)\n",
    "        print(loss)\n",
    "        #print(loss.shape)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "for i, data in enumerate(testloader):\n",
    "    with torch.no_grad():\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output = net(inputs)\n",
    "        imshow(torchvision.utils.make_grid(inputs.detach().cpu()))\n",
    "        imshow(torchvision.utils.make_grid(output.detach().cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
